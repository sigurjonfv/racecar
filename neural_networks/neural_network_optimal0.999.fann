FANN_FLO_2.1
num_layers=4
learning_rate=0.010000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=7 7 10 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (7, 5, 5.00000000000000000000e-01) (7, 5, 5.00000000000000000000e-01) (7, 5, 5.00000000000000000000e-01) (7, 5, 5.00000000000000000000e-01) (7, 5, 5.00000000000000000000e-01) (7, 5, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (7, 5, 5.00000000000000000000e-01) (7, 5, 5.00000000000000000000e-01) (7, 5, 5.00000000000000000000e-01) (7, 5, 5.00000000000000000000e-01) (7, 5, 5.00000000000000000000e-01) (7, 5, 5.00000000000000000000e-01) (7, 5, 5.00000000000000000000e-01) (7, 5, 5.00000000000000000000e-01) (7, 5, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (10, 5, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -7.40377545356750488281e-01) (1, 1.96587339043617248535e-01) (2, -1.10126483440399169922e+00) (3, 9.85515594482421875000e-01) (4, -2.02553653717041015625e+00) (5, 1.36936628818511962891e+00) (6, -3.58984321355819702148e-01) (0, 2.57868361473083496094e+00) (1, 5.63927793502807617188e+00) (2, 1.23873427510261535645e-01) (3, 3.88541400432586669922e-01) (4, 1.18351686000823974609e+00) (5, 1.05213880538940429688e+00) (6, 9.90060567855834960938e-02) (0, -2.86704599857330322266e-01) (1, -6.78987324237823486328e-01) (2, -5.20374923944473266602e-02) (3, -3.09320120140910148621e-03) (4, -2.85945564508438110352e-01) (5, -1.58737346529960632324e-01) (6, 3.14267277717590332031e-02) (0, -2.84422010183334350586e-01) (1, -2.28658199310302734375e-01) (2, -6.89083576202392578125e-01) (3, -3.70576113462448120117e-01) (4, -8.79906654357910156250e-01) (5, -3.81877511739730834961e-01) (6, 4.74695712327957153320e-01) (0, -1.16175472736358642578e+00) (1, 3.84037345647811889648e-01) (2, -8.38796496391296386719e-01) (3, -6.73113524913787841797e-01) (4, -1.37247896194458007812e+00) (5, -4.46000367403030395508e-01) (6, 6.26554787158966064453e-01) (0, 8.56769859790802001953e-01) (1, -1.47632408142089843750e+00) (2, -5.13570494949817657471e-02) (3, 2.75681793689727783203e-01) (4, 2.63143002986907958984e-01) (5, -2.42506638169288635254e-01) (6, -2.60873464867472648621e-03) (7, -4.15399163961410522461e-01) (8, -3.09970736503601074219e-01) (9, -1.35734854266047477722e-02) (10, -7.64062762260437011719e-01) (11, 2.40482352674007415771e-02) (12, 1.51527244597673416138e-02) (13, -9.24102142453193664551e-02) (7, -1.93273648619651794434e-01) (8, -3.16502183675765991211e-01) (9, 8.81374552845954895020e-02) (10, -4.09260869026184082031e-01) (11, 1.52649998664855957031e-01) (12, 2.24548116326332092285e-01) (13, 9.28836315870285034180e-02) (7, 5.22107146680355072021e-02) (8, 1.95149809122085571289e-01) (9, 5.52966371178627014160e-02) (10, 1.41037210822105407715e-01) (11, -6.11979514360427856445e-02) (12, -6.05073906481266021729e-02) (13, -4.99786138534545898438e-02) (7, -1.74285829067230224609e-01) (8, -2.96010047197341918945e-01) (9, -7.13653340935707092285e-02) (10, -3.03724408149719238281e-01) (11, 2.02363580465316772461e-01) (12, 1.17015272378921508789e-01) (13, 2.53393733873963356018e-03) (7, 2.05584734678268432617e-01) (8, 2.42623195052146911621e-01) (9, -4.61546145379543304443e-02) (10, 4.19535875320434570312e-01) (11, -9.53880622982978820801e-02) (12, -1.75473187118768692017e-02) (13, 3.87156568467617034912e-02) (7, -2.05605372786521911621e-01) (8, -2.27404594421386718750e-01) (9, 8.35302099585533142090e-02) (10, -3.54157209396362304688e-01) (11, 1.30036830902099609375e-01) (12, 1.54075056314468383789e-01) (13, 1.86210796236991882324e-02) (7, -1.89646810293197631836e-01) (8, -1.76206409931182861328e-01) (9, -6.04149922728538513184e-02) (10, -3.46912205219268798828e-01) (11, 1.74717858433723449707e-01) (12, 1.86442241072654724121e-01) (13, -2.34628990292549133301e-02) (7, -4.81583960354328155518e-02) (8, -7.23015964031219482422e-02) (9, 2.08194721490144729614e-02) (10, -1.25315850600600242615e-02) (11, 1.13652683794498443604e-01) (12, -2.46101487427949905396e-02) (13, -3.05322036147117614746e-02) (7, -3.86513583362102508545e-03) (8, 4.42531742155551910400e-02) (9, 7.42923766374588012695e-02) (10, 3.00895273685455322266e-02) (11, -4.87921051681041717529e-02) (12, 6.74891248345375061035e-02) (13, 7.52284452319145202637e-02) (14, 5.04208266735076904297e-01) (15, 2.78000026941299438477e-01) (16, -1.02566368877887725830e-01) (17, 1.87186434864997863770e-01) (18, -2.68141150474548339844e-01) (19, 2.26183503866195678711e-01) (20, 2.01125964522361755371e-01) (21, -1.21657690033316612244e-02) (22, -4.73898183554410934448e-03) (23, -4.40275549888610839844e-01) 
